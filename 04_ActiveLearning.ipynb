{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit numpy pandas matplotlib scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxH3NZmn9ZNg",
        "outputId": "bdc9959c-72cc-473b-d046-608718c402a5"
      },
      "id": "SxH3NZmn9ZNg",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Using cached rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading rdkit-2025.3.5-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2025.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "808bbd59",
      "metadata": {
        "id": "808bbd59"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import MACCSkeys\n",
        "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
        "from rdkit import DataStructs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAPER_COLORS = ['#1B9E77', '#7570B3', '#66A61E']"
      ],
      "metadata": {
        "id": "feqT1v8-7PlG"
      },
      "id": "feqT1v8-7PlG",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "11593385",
      "metadata": {
        "id": "11593385"
      },
      "outputs": [],
      "source": [
        "class ActiveLearningLoop:\n",
        "    def __init__(self, data_df, fingerprint_type='morgan', model_type='RF',\n",
        "                 model_params=None, preset='large',\n",
        "                 init_fraction=0.20, selection_fraction=0.02, top_fraction=0.01,\n",
        "                 max_iterations=5, random_state=42, test_size=0.2):\n",
        "        self.data = data_df.reset_index(drop=True)\n",
        "        self.fingerprint_type = fingerprint_type\n",
        "        self.model_type = model_type\n",
        "        self.model_params = model_params or {}\n",
        "        self.preset = preset\n",
        "        self.init_fraction = init_fraction\n",
        "        self.selection_fraction = selection_fraction\n",
        "        self.top_fraction = top_fraction\n",
        "        self.max_iterations = max_iterations\n",
        "        self.random_state = random_state\n",
        "        self.test_size = test_size\n",
        "        self.smiles_dict = dict(zip(self.data['ID'], self.data['smiles']))\n",
        "        self.affinity_dict = dict(zip(self.data['ID'], self.data['affinity']))\n",
        "        self.fingerprint_cache = {}\n",
        "        self.evaluated_ids = set()\n",
        "        self.all_ids = self.data[\"ID\"].tolist()\n",
        "        self.progress_log = []\n",
        "        self.fp_length = {'morgan': 2048, 'maccs': 167, 'map4': 1024}[fingerprint_type]\n",
        "        self.morgan_generator = GetMorganGenerator(radius=3, fpSize=2048)\n",
        "\n",
        "    def _fp_morgan(self, smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return np.zeros(2048, dtype=float)\n",
        "        fp = self.morgan_generator.GetFingerprint(mol)\n",
        "        arr = np.zeros((2048,), dtype=int)\n",
        "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "        return arr.astype(float)\n",
        "\n",
        "    def _fp_maccs(self, smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return np.zeros(167, dtype=float)\n",
        "        fp = MACCSkeys.GenMACCSKeys(mol)\n",
        "        arr = np.zeros((167,), dtype=int)\n",
        "        DataStructs.ConvertToNumpyArray(fp, arr)\n",
        "        return arr.astype(float)\n",
        "\n",
        "    def smiles_to_fingerprint(self, smiles):\n",
        "        try:\n",
        "            if self.fingerprint_type == 'maccs':\n",
        "                return self._fp_maccs(smiles)\n",
        "            else:\n",
        "                return self._fp_morgan(smiles)\n",
        "        except:\n",
        "            return np.zeros(self.fp_length, dtype=float)\n",
        "\n",
        "    def compute_fingerprints(self):\n",
        "        for idx, smiles in self.smiles_dict.items():\n",
        "            self.fingerprint_cache[idx] = self.smiles_to_fingerprint(smiles)\n",
        "\n",
        "    def _make_model(self):\n",
        "        if self.model_type == 'RF':\n",
        "            defaults = dict(n_estimators=600, max_features=0.3,\n",
        "                            n_jobs=-1, random_state=self.random_state)\n",
        "            return RandomForestRegressor(**defaults)\n",
        "        if self.model_type == 'SVR':\n",
        "            defaults = dict(kernel='rbf', C=5.0, epsilon=0.1, gamma='scale')\n",
        "            return Pipeline([('scaler', StandardScaler()), ('svr', SVR(**defaults))])\n",
        "        if self.model_type == 'MLR':\n",
        "            defaults = dict(alpha=1.0)\n",
        "            return Pipeline([('scaler', StandardScaler()), ('ridge', Ridge(**defaults))])\n",
        "\n",
        "    def get_top_affinities(self, top_percent):\n",
        "        df = self.data[['ID', 'affinity']].dropna().copy()\n",
        "        df = df.sort_values('affinity', ascending=True)\n",
        "        top_n = max(1, int(top_percent * len(df)))\n",
        "        top_ids = set(df.head(top_n)['ID'].tolist())\n",
        "        return top_ids, top_n\n",
        "\n",
        "    def run(self):\n",
        "        rng = np.random.RandomState(self.random_state)\n",
        "        n_initial = max(1, int(self.init_fraction * len(self.all_ids)))\n",
        "        selection_size = max(1, int(self.selection_fraction * len(self.all_ids)))\n",
        "        top_ids, top_n = self.get_top_affinities(top_percent=self.top_fraction)\n",
        "        self.compute_fingerprints()\n",
        "        self.evaluated_ids = set(rng.choice(self.all_ids, n_initial, replace=False))\n",
        "        captured0 = self.evaluated_ids.intersection(top_ids)\n",
        "        self.progress_log.append({'iteration': 0, 'evaluated': len(self.evaluated_ids),\n",
        "                                  'recovered': len(captured0),\n",
        "                                  'recovered_pct': 100.0 * len(captured0) / max(1, top_n)})\n",
        "        for iteration in range(self.max_iterations):\n",
        "            print(f\"\\nIteration {iteration+1}/{self.max_iterations}\")\n",
        "            X_train, y_train = [], []\n",
        "            for idx in self.evaluated_ids:\n",
        "                y = self.affinity_dict.get(idx, None)\n",
        "                if y is not None and not np.isnan(y):\n",
        "                    X_train.append(self.fingerprint_cache[idx])\n",
        "                    y_train.append(y)\n",
        "            X_train = np.array(X_train); y_train = np.array(y_train)\n",
        "            if len(X_train) == 0:\n",
        "                break\n",
        "            model = self._make_model()\n",
        "            model.fit(X_train, y_train)\n",
        "            candidates = list(set(self.all_ids) - self.evaluated_ids)\n",
        "            if not candidates:\n",
        "                break\n",
        "            X_candidates = np.stack([self.fingerprint_cache[c] for c in candidates], axis=0)\n",
        "            preds = model.predict(X_candidates)\n",
        "            order = np.argsort(preds)\n",
        "            take = min(selection_size, len(candidates))\n",
        "            selected_ids = [candidates[i] for i in order[:take]]\n",
        "            self.evaluated_ids.update(selected_ids)\n",
        "            captured = self.evaluated_ids.intersection(top_ids)\n",
        "            self.progress_log.append({'iteration': iteration + 1,\n",
        "                                      'evaluated': len(self.evaluated_ids),\n",
        "                                      'recovered': len(captured),\n",
        "                                      'recovered_pct': 100.0 * len(captured) / max(1, top_n)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "eb2dc266",
      "metadata": {
        "id": "eb2dc266"
      },
      "outputs": [],
      "source": [
        "def build_progress_df(loop):\n",
        "    df = pd.DataFrame(loop.progress_log).copy()\n",
        "    total = len(loop.all_ids)\n",
        "    df['explored'] = df['evaluated']\n",
        "    df['explored_pct'] = 100.0 * df['evaluated'] / max(1, total)\n",
        "    return df\n",
        "\n",
        "def plot_recovery_curves(progress_by_model, fingerprint_type, init_fraction, top_fraction):\n",
        "    plt.figure()\n",
        "    for i, (model, dfp) in enumerate(progress_by_model.items()):\n",
        "        color = PAPER_COLORS[i % len(PAPER_COLORS)]\n",
        "        plt.plot(dfp['explored'], dfp['recovered_pct'], marker='o',\n",
        "                 label=model, linewidth=2, markersize=5, color=color)\n",
        "    plt.xlabel(\"Molecules explored\")\n",
        "    plt.ylabel(\"Percentage of top-n scores found\")\n",
        "    plt.title(f\"Init={init_fraction:.0%}, Fingerprint={fingerprint_type}, Top={int(top_fraction*100)}%\")\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def run_models_and_plot(df, fingerprint_type='morgan', models=('RF','SVR','MLR'),\n",
        "                        init_fraction=0.10, selection_fraction=0.02, top_fraction=0.01,\n",
        "                        max_iterations=5, random_state=42, test_size=0.2):\n",
        "    progress_by_model = {}\n",
        "    for model_type in models:\n",
        "        loop = ActiveLearningLoop(df, fingerprint_type=fingerprint_type,\n",
        "                                  model_type=model_type, preset='large',\n",
        "                                  init_fraction=init_fraction,\n",
        "                                  selection_fraction=selection_fraction,\n",
        "                                  top_fraction=top_fraction,\n",
        "                                  max_iterations=max_iterations,\n",
        "                                  random_state=random_state,\n",
        "                                  test_size=test_size)\n",
        "        loop.run()\n",
        "        df_prog = build_progress_df(loop)\n",
        "        progress_by_model[model_type] = df_prog\n",
        "    plot_recovery_curves(progress_by_model, fingerprint_type, init_fraction, top_fraction)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"df_merged.csv\")\n",
        "print(df.head())\n",
        "print(f\"Total compounds loaded: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYiygq1Z7l9H",
        "outputId": "3895d799-b620-4aa4-cb41-17b331a99516"
      },
      "id": "GYiygq1Z7l9H",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID                                             smiles  \\\n",
            "0   0  CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=C(COC...   \n",
            "1   1  O=C(O)C1=CC=CC(/C=C2\\C[C@H]3C[C@@H](O)[C@H](/C...   \n",
            "2   2  CC(C)(C)C(=O)OCOC(=O)[C@@H]1N2C(=O)[C@@H](NC(=...   \n",
            "3   3  CCCC(=O)O[C@]1(C(=O)CO)CC[C@H]2[C@@H]3CCC4=CC(...   \n",
            "4   4  CCNC(=O)CCC/C=C\\C[C@@H]1[C@@H](/C=C/[C@@H](O)C...   \n",
            "\n",
            "                                    Largest Fragment  \\\n",
            "0  CCCC(=O)O[C@]1(C(=O)CO)CC[C@H]2[C@@H]3CCC4=CC(...   \n",
            "1  CCC(=O)O[C@]1(C(=O)COC(C)=O)CC[C@H]2[C@@H]3C[C...   \n",
            "2  COC1=C(C(=O)OCCN(C)C)[C@H]2C[C@@H]3c4[nH]c5cc(...   \n",
            "3  CN(C(=O)/C=C/c1ccoc1)[C@@H]1CC[C@@]2(O)[C@H]3C...   \n",
            "4  C[C@]12C=C(C=O)C(=O)C=C1CC[C@@H]1[C@@H]2[C@H](...   \n",
            "\n",
            "                                  Canonical_Tautomer Warnings  affinity  \n",
            "0  CCCC(=O)O[C@]1(C(O)C=O)CC[C@H]2[C@@H]3CCC4=CC(...       {}      -7.0  \n",
            "1  CCC(=O)O[C@]1(C(=O)COC(C)=O)CC[C@H]2[C@@H]3C[C...       {}      -8.3  \n",
            "2  COC1=C(C(=O)OCC[NH+](C)C)[C@H]2C[C@@H]3c4[nH]c...       {}      -7.9  \n",
            "3  CN(C(=O)/C=C/c1ccoc1)[C@@H]1CC[C@@]2(O)[C@H]3C...       {}      -8.7  \n",
            "4  C[C@]12C=C(C=O)C(=O)C=C1CC[C@@H]1[C@@H]2[C@H](...       {}      -8.8  \n",
            "Total compounds loaded: 164061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for init_f in [0.01, 0.05, 0.10]:\n",
        "    run_models_and_plot(df, fingerprint_type='morgan',\n",
        "                        models=('RF','SVR','MLR'),\n",
        "                        init_fraction=init_f,\n",
        "                        selection_fraction=0.02,\n",
        "                        top_fraction=0.01,\n",
        "                        max_iterations=5,\n",
        "                        random_state=42,\n",
        "                        test_size=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LTiI6Dh7qGa",
        "outputId": "01f069f6-7d65-47ce-a92c-5409743da669"
      },
      "id": "0LTiI6Dh7qGa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[04:17:24] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iteration 1/5\n",
            "\n",
            "Iteration 2/5\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}